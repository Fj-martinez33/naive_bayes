{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>loved it i loooooooooooooovvved it because it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>all time legendary game the birthday party le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>ads are way to heavy listen to the bad review...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>fun works perfectly well. ads aren't as annoy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>they're everywhere i see angry birds everywhe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  polarity\n",
       "0     privacy at least put some option appear offli...         0\n",
       "1     messenger issues ever since the last update, ...         0\n",
       "2     profile any time my wife or anybody has more ...         0\n",
       "3     the new features suck for those of us who don...         0\n",
       "4     forced reload on uploading pic on replying co...         0\n",
       "..                                                 ...       ...\n",
       "886   loved it i loooooooooooooovvved it because it...         1\n",
       "887   all time legendary game the birthday party le...         1\n",
       "888   ads are way to heavy listen to the bad review...         0\n",
       "889   fun works perfectly well. ads aren't as annoy...         1\n",
       "890   they're everywhere i see angry birds everywhe...         1\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\"\n",
    "\n",
    "def DataCompiler(url, sep = \",\"):\n",
    "    data = pd.read_csv(url)\n",
    "    data.to_csv(\"../data/raw/reviews.csv\")\n",
    "    return data\n",
    "\n",
    "data = DataCompiler(data_url)\n",
    "\n",
    "data.drop(\"package_name\", axis = 1, inplace = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StripPhase(dataset, col):\n",
    "        dataset[col] = dataset[col].str.strip().str.lower()\n",
    "        return dataset\n",
    "\n",
    "StripPhase(data, \"review\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"review\"], data[\"polarity\"], test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeString(train, test):\n",
    "    vec_model = CountVectorizer(stop_words = \"english\")\n",
    "    x_train_vect = vec_model.fit_transform(train).toarray().squeeze()\n",
    "    x_test_vect = vec_model.transform(test).toarray().squeeze()\n",
    "    return x_train_vect, x_test_vect\n",
    "\n",
    "x_train_vect, x_test_vect = VectorizeString(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Index': 'MultinomialNB()',\n",
       "  'train_score': 0.9606741573033708,\n",
       "  'test_score': 0.8156424581005587},\n",
       " {'Index': 'GaussianNB()',\n",
       "  'train_score': 0.9859550561797753,\n",
       "  'test_score': 0.8044692737430168},\n",
       " {'Index': 'BernoulliNB()',\n",
       "  'train_score': 0.9199438202247191,\n",
       "  'test_score': 0.770949720670391}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_models = [MultinomialNB(), GaussianNB(), BernoulliNB()]\n",
    "\n",
    "def TrainingModel(t_model):\n",
    "    results = []\n",
    "    models = []\n",
    "\n",
    "    for i in range(len(t_model)):\n",
    "\n",
    "        model = t_model[i]\n",
    "        model.fit(x_train_vect, y_train)\n",
    "        models.append(model)\n",
    "\n",
    "        y_test_pred = model.predict(x_test_vect)\n",
    "        y_train_pred = model.predict(x_train_vect)\n",
    "        result = {\"Index\" : str(t_models[i]), \"train_score\" : accuracy_score(y_train, y_train_pred), \"test_score\" : accuracy_score(y_test, y_test_pred)}\n",
    "        results.append(result)\n",
    "\n",
    "    return results, models\n",
    "\n",
    "pre_results, pre_models = TrainingModel(t_models)\n",
    "\n",
    "pre_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El mejor modelo es el Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': array([  0.        ,   0.1001001 ,   0.2002002 ,   0.3003003 ,\n",
       "          0.4004004 ,   0.5005005 ,   0.6006006 ,   0.7007007 ,\n",
       "          0.8008008 ,   0.9009009 ,   1.001001  ,   1.1011011 ,\n",
       "          1.2012012 ,   1.3013013 ,   1.4014014 ,   1.5015015 ,\n",
       "          1.6016016 ,   1.7017017 ,   1.8018018 ,   1.9019019 ,\n",
       "          2.002002  ,   2.1021021 ,   2.2022022 ,   2.3023023 ,\n",
       "          2.4024024 ,   2.5025025 ,   2.6026026 ,   2.7027027 ,\n",
       "          2.8028028 ,   2.9029029 ,   3.003003  ,   3.1031031 ,\n",
       "          3.2032032 ,   3.3033033 ,   3.4034034 ,   3.5035035 ,\n",
       "          3.6036036 ,   3.7037037 ,   3.8038038 ,   3.9039039 ,\n",
       "          4.004004  ,   4.1041041 ,   4.2042042 ,   4.3043043 ,\n",
       "          4.4044044 ,   4.5045045 ,   4.6046046 ,   4.7047047 ,\n",
       "          4.8048048 ,   4.9049049 ,   5.00500501,   5.10510511,\n",
       "          5.20520521,   5.30530531,   5.40540541,   5.50550551,\n",
       "          5.60560561,   5.70570571,   5.80580581,   5.90590591,\n",
       "          6.00600601,   6.10610611,   6.20620621,   6.30630631,\n",
       "          6.40640641,   6.50650651,   6.60660661,   6.70670671,\n",
       "          6.80680681,   6.90690691,   7.00700701,   7.10710711,\n",
       "          7.20720721,   7.30730731,   7.40740741,   7.50750751,\n",
       "          7.60760761,   7.70770771,   7.80780781,   7.90790791,\n",
       "          8.00800801,   8.10810811,   8.20820821,   8.30830831,\n",
       "          8.40840841,   8.50850851,   8.60860861,   8.70870871,\n",
       "          8.80880881,   8.90890891,   9.00900901,   9.10910911,\n",
       "          9.20920921,   9.30930931,   9.40940941,   9.50950951,\n",
       "          9.60960961,   9.70970971,   9.80980981,   9.90990991,\n",
       "         10.01001001,  10.11011011,  10.21021021,  10.31031031,\n",
       "         10.41041041,  10.51051051,  10.61061061,  10.71071071,\n",
       "         10.81081081,  10.91091091,  11.01101101,  11.11111111,\n",
       "         11.21121121,  11.31131131,  11.41141141,  11.51151151,\n",
       "         11.61161161,  11.71171171,  11.81181181,  11.91191191,\n",
       "         12.01201201,  12.11211211,  12.21221221,  12.31231231,\n",
       "         12.41241241,  12.51251251,  12.61261261,  12.71271271,\n",
       "         12.81281281,  12.91291291,  13.01301301,  13.11311311,\n",
       "         13.21321321,  13.31331331,  13.41341341,  13.51351351,\n",
       "         13.61361361,  13.71371371,  13.81381381,  13.91391391,\n",
       "         14.01401401,  14.11411411,  14.21421421,  14.31431431,\n",
       "         14.41441441,  14.51451451,  14.61461461,  14.71471471,\n",
       "         14.81481481,  14.91491491,  15.01501502,  15.11511512,\n",
       "         15.21521522,  15.31531532,  15.41541542,  15.51551552,\n",
       "         15.61561562,  15.71571572,  15.81581582,  15.91591592,\n",
       "         16.01601602,  16.11611612,  16.21621622,  16.31631632,\n",
       "         16.41641642,  16.51651652,  16.61661662,  16.71671672,\n",
       "         16.81681682,  16.91691692,  17.01701702,  17.11711712,\n",
       "         17.21721722,  17.31731732,  17.41741742,  17.51751752,\n",
       "         17.61761762,  17.71771772,  17.81781782,  17.91791792,\n",
       "         18.01801802,  18.11811812,  18.21821822,  18.31831832,\n",
       "         18.41841842,  18.51851852,  18.61861862,  18.71871872,\n",
       "         18.81881882,  18.91891892,  19.01901902,  19.11911912,\n",
       "         19.21921922,  19.31931932,  19.41941942,  19.51951952,\n",
       "         19.61961962,  19.71971972,  19.81981982,  19.91991992,\n",
       "         20.02002002,  20.12012012,  20.22022022,  20.32032032,\n",
       "         20.42042042,  20.52052052,  20.62062062,  20.72072072,\n",
       "         20.82082082,  20.92092092,  21.02102102,  21.12112112,\n",
       "         21.22122122,  21.32132132,  21.42142142,  21.52152152,\n",
       "         21.62162162,  21.72172172,  21.82182182,  21.92192192,\n",
       "         22.02202202,  22.12212212,  22.22222222,  22.32232232,\n",
       "         22.42242242,  22.52252252,  22.62262262,  22.72272272,\n",
       "         22.82282282,  22.92292292,  23.02302302,  23.12312312,\n",
       "         23.22322322,  23.32332332,  23.42342342,  23.52352352,\n",
       "         23.62362362,  23.72372372,  23.82382382,  23.92392392,\n",
       "         24.02402402,  24.12412412,  24.22422422,  24.32432432,\n",
       "         24.42442442,  24.52452452,  24.62462462,  24.72472472,\n",
       "         24.82482482,  24.92492492,  25.02502503,  25.12512513,\n",
       "         25.22522523,  25.32532533,  25.42542543,  25.52552553,\n",
       "         25.62562563,  25.72572573,  25.82582583,  25.92592593,\n",
       "         26.02602603,  26.12612613,  26.22622623,  26.32632633,\n",
       "         26.42642643,  26.52652653,  26.62662663,  26.72672673,\n",
       "         26.82682683,  26.92692693,  27.02702703,  27.12712713,\n",
       "         27.22722723,  27.32732733,  27.42742743,  27.52752753,\n",
       "         27.62762763,  27.72772773,  27.82782783,  27.92792793,\n",
       "         28.02802803,  28.12812813,  28.22822823,  28.32832833,\n",
       "         28.42842843,  28.52852853,  28.62862863,  28.72872873,\n",
       "         28.82882883,  28.92892893,  29.02902903,  29.12912913,\n",
       "         29.22922923,  29.32932933,  29.42942943,  29.52952953,\n",
       "         29.62962963,  29.72972973,  29.82982983,  29.92992993,\n",
       "         30.03003003,  30.13013013,  30.23023023,  30.33033033,\n",
       "         30.43043043,  30.53053053,  30.63063063,  30.73073073,\n",
       "         30.83083083,  30.93093093,  31.03103103,  31.13113113,\n",
       "         31.23123123,  31.33133133,  31.43143143,  31.53153153,\n",
       "         31.63163163,  31.73173173,  31.83183183,  31.93193193,\n",
       "         32.03203203,  32.13213213,  32.23223223,  32.33233233,\n",
       "         32.43243243,  32.53253253,  32.63263263,  32.73273273,\n",
       "         32.83283283,  32.93293293,  33.03303303,  33.13313313,\n",
       "         33.23323323,  33.33333333,  33.43343343,  33.53353353,\n",
       "         33.63363363,  33.73373373,  33.83383383,  33.93393393,\n",
       "         34.03403403,  34.13413413,  34.23423423,  34.33433433,\n",
       "         34.43443443,  34.53453453,  34.63463463,  34.73473473,\n",
       "         34.83483483,  34.93493493,  35.03503504,  35.13513514,\n",
       "         35.23523524,  35.33533534,  35.43543544,  35.53553554,\n",
       "         35.63563564,  35.73573574,  35.83583584,  35.93593594,\n",
       "         36.03603604,  36.13613614,  36.23623624,  36.33633634,\n",
       "         36.43643644,  36.53653654,  36.63663664,  36.73673674,\n",
       "         36.83683684,  36.93693694,  37.03703704,  37.13713714,\n",
       "         37.23723724,  37.33733734,  37.43743744,  37.53753754,\n",
       "         37.63763764,  37.73773774,  37.83783784,  37.93793794,\n",
       "         38.03803804,  38.13813814,  38.23823824,  38.33833834,\n",
       "         38.43843844,  38.53853854,  38.63863864,  38.73873874,\n",
       "         38.83883884,  38.93893894,  39.03903904,  39.13913914,\n",
       "         39.23923924,  39.33933934,  39.43943944,  39.53953954,\n",
       "         39.63963964,  39.73973974,  39.83983984,  39.93993994,\n",
       "         40.04004004,  40.14014014,  40.24024024,  40.34034034,\n",
       "         40.44044044,  40.54054054,  40.64064064,  40.74074074,\n",
       "         40.84084084,  40.94094094,  41.04104104,  41.14114114,\n",
       "         41.24124124,  41.34134134,  41.44144144,  41.54154154,\n",
       "         41.64164164,  41.74174174,  41.84184184,  41.94194194,\n",
       "         42.04204204,  42.14214214,  42.24224224,  42.34234234,\n",
       "         42.44244244,  42.54254254,  42.64264264,  42.74274274,\n",
       "         42.84284284,  42.94294294,  43.04304304,  43.14314314,\n",
       "         43.24324324,  43.34334334,  43.44344344,  43.54354354,\n",
       "         43.64364364,  43.74374374,  43.84384384,  43.94394394,\n",
       "         44.04404404,  44.14414414,  44.24424424,  44.34434434,\n",
       "         44.44444444,  44.54454454,  44.64464464,  44.74474474,\n",
       "         44.84484484,  44.94494494,  45.04504505,  45.14514515,\n",
       "         45.24524525,  45.34534535,  45.44544545,  45.54554555,\n",
       "         45.64564565,  45.74574575,  45.84584585,  45.94594595,\n",
       "         46.04604605,  46.14614615,  46.24624625,  46.34634635,\n",
       "         46.44644645,  46.54654655,  46.64664665,  46.74674675,\n",
       "         46.84684685,  46.94694695,  47.04704705,  47.14714715,\n",
       "         47.24724725,  47.34734735,  47.44744745,  47.54754755,\n",
       "         47.64764765,  47.74774775,  47.84784785,  47.94794795,\n",
       "         48.04804805,  48.14814815,  48.24824825,  48.34834835,\n",
       "         48.44844845,  48.54854855,  48.64864865,  48.74874875,\n",
       "         48.84884885,  48.94894895,  49.04904905,  49.14914915,\n",
       "         49.24924925,  49.34934935,  49.44944945,  49.54954955,\n",
       "         49.64964965,  49.74974975,  49.84984985,  49.94994995,\n",
       "         50.05005005,  50.15015015,  50.25025025,  50.35035035,\n",
       "         50.45045045,  50.55055055,  50.65065065,  50.75075075,\n",
       "         50.85085085,  50.95095095,  51.05105105,  51.15115115,\n",
       "         51.25125125,  51.35135135,  51.45145145,  51.55155155,\n",
       "         51.65165165,  51.75175175,  51.85185185,  51.95195195,\n",
       "         52.05205205,  52.15215215,  52.25225225,  52.35235235,\n",
       "         52.45245245,  52.55255255,  52.65265265,  52.75275275,\n",
       "         52.85285285,  52.95295295,  53.05305305,  53.15315315,\n",
       "         53.25325325,  53.35335335,  53.45345345,  53.55355355,\n",
       "         53.65365365,  53.75375375,  53.85385385,  53.95395395,\n",
       "         54.05405405,  54.15415415,  54.25425425,  54.35435435,\n",
       "         54.45445445,  54.55455455,  54.65465465,  54.75475475,\n",
       "         54.85485485,  54.95495495,  55.05505506,  55.15515516,\n",
       "         55.25525526,  55.35535536,  55.45545546,  55.55555556,\n",
       "         55.65565566,  55.75575576,  55.85585586,  55.95595596,\n",
       "         56.05605606,  56.15615616,  56.25625626,  56.35635636,\n",
       "         56.45645646,  56.55655656,  56.65665666,  56.75675676,\n",
       "         56.85685686,  56.95695696,  57.05705706,  57.15715716,\n",
       "         57.25725726,  57.35735736,  57.45745746,  57.55755756,\n",
       "         57.65765766,  57.75775776,  57.85785786,  57.95795796,\n",
       "         58.05805806,  58.15815816,  58.25825826,  58.35835836,\n",
       "         58.45845846,  58.55855856,  58.65865866,  58.75875876,\n",
       "         58.85885886,  58.95895896,  59.05905906,  59.15915916,\n",
       "         59.25925926,  59.35935936,  59.45945946,  59.55955956,\n",
       "         59.65965966,  59.75975976,  59.85985986,  59.95995996,\n",
       "         60.06006006,  60.16016016,  60.26026026,  60.36036036,\n",
       "         60.46046046,  60.56056056,  60.66066066,  60.76076076,\n",
       "         60.86086086,  60.96096096,  61.06106106,  61.16116116,\n",
       "         61.26126126,  61.36136136,  61.46146146,  61.56156156,\n",
       "         61.66166166,  61.76176176,  61.86186186,  61.96196196,\n",
       "         62.06206206,  62.16216216,  62.26226226,  62.36236236,\n",
       "         62.46246246,  62.56256256,  62.66266266,  62.76276276,\n",
       "         62.86286286,  62.96296296,  63.06306306,  63.16316316,\n",
       "         63.26326326,  63.36336336,  63.46346346,  63.56356356,\n",
       "         63.66366366,  63.76376376,  63.86386386,  63.96396396,\n",
       "         64.06406406,  64.16416416,  64.26426426,  64.36436436,\n",
       "         64.46446446,  64.56456456,  64.66466466,  64.76476476,\n",
       "         64.86486486,  64.96496496,  65.06506507,  65.16516517,\n",
       "         65.26526527,  65.36536537,  65.46546547,  65.56556557,\n",
       "         65.66566567,  65.76576577,  65.86586587,  65.96596597,\n",
       "         66.06606607,  66.16616617,  66.26626627,  66.36636637,\n",
       "         66.46646647,  66.56656657,  66.66666667,  66.76676677,\n",
       "         66.86686687,  66.96696697,  67.06706707,  67.16716717,\n",
       "         67.26726727,  67.36736737,  67.46746747,  67.56756757,\n",
       "         67.66766767,  67.76776777,  67.86786787,  67.96796797,\n",
       "         68.06806807,  68.16816817,  68.26826827,  68.36836837,\n",
       "         68.46846847,  68.56856857,  68.66866867,  68.76876877,\n",
       "         68.86886887,  68.96896897,  69.06906907,  69.16916917,\n",
       "         69.26926927,  69.36936937,  69.46946947,  69.56956957,\n",
       "         69.66966967,  69.76976977,  69.86986987,  69.96996997,\n",
       "         70.07007007,  70.17017017,  70.27027027,  70.37037037,\n",
       "         70.47047047,  70.57057057,  70.67067067,  70.77077077,\n",
       "         70.87087087,  70.97097097,  71.07107107,  71.17117117,\n",
       "         71.27127127,  71.37137137,  71.47147147,  71.57157157,\n",
       "         71.67167167,  71.77177177,  71.87187187,  71.97197197,\n",
       "         72.07207207,  72.17217217,  72.27227227,  72.37237237,\n",
       "         72.47247247,  72.57257257,  72.67267267,  72.77277277,\n",
       "         72.87287287,  72.97297297,  73.07307307,  73.17317317,\n",
       "         73.27327327,  73.37337337,  73.47347347,  73.57357357,\n",
       "         73.67367367,  73.77377377,  73.87387387,  73.97397397,\n",
       "         74.07407407,  74.17417417,  74.27427427,  74.37437437,\n",
       "         74.47447447,  74.57457457,  74.67467467,  74.77477477,\n",
       "         74.87487487,  74.97497497,  75.07507508,  75.17517518,\n",
       "         75.27527528,  75.37537538,  75.47547548,  75.57557558,\n",
       "         75.67567568,  75.77577578,  75.87587588,  75.97597598,\n",
       "         76.07607608,  76.17617618,  76.27627628,  76.37637638,\n",
       "         76.47647648,  76.57657658,  76.67667668,  76.77677678,\n",
       "         76.87687688,  76.97697698,  77.07707708,  77.17717718,\n",
       "         77.27727728,  77.37737738,  77.47747748,  77.57757758,\n",
       "         77.67767768,  77.77777778,  77.87787788,  77.97797798,\n",
       "         78.07807808,  78.17817818,  78.27827828,  78.37837838,\n",
       "         78.47847848,  78.57857858,  78.67867868,  78.77877878,\n",
       "         78.87887888,  78.97897898,  79.07907908,  79.17917918,\n",
       "         79.27927928,  79.37937938,  79.47947948,  79.57957958,\n",
       "         79.67967968,  79.77977978,  79.87987988,  79.97997998,\n",
       "         80.08008008,  80.18018018,  80.28028028,  80.38038038,\n",
       "         80.48048048,  80.58058058,  80.68068068,  80.78078078,\n",
       "         80.88088088,  80.98098098,  81.08108108,  81.18118118,\n",
       "         81.28128128,  81.38138138,  81.48148148,  81.58158158,\n",
       "         81.68168168,  81.78178178,  81.88188188,  81.98198198,\n",
       "         82.08208208,  82.18218218,  82.28228228,  82.38238238,\n",
       "         82.48248248,  82.58258258,  82.68268268,  82.78278278,\n",
       "         82.88288288,  82.98298298,  83.08308308,  83.18318318,\n",
       "         83.28328328,  83.38338338,  83.48348348,  83.58358358,\n",
       "         83.68368368,  83.78378378,  83.88388388,  83.98398398,\n",
       "         84.08408408,  84.18418418,  84.28428428,  84.38438438,\n",
       "         84.48448448,  84.58458458,  84.68468468,  84.78478478,\n",
       "         84.88488488,  84.98498498,  85.08508509,  85.18518519,\n",
       "         85.28528529,  85.38538539,  85.48548549,  85.58558559,\n",
       "         85.68568569,  85.78578579,  85.88588589,  85.98598599,\n",
       "         86.08608609,  86.18618619,  86.28628629,  86.38638639,\n",
       "         86.48648649,  86.58658659,  86.68668669,  86.78678679,\n",
       "         86.88688689,  86.98698699,  87.08708709,  87.18718719,\n",
       "         87.28728729,  87.38738739,  87.48748749,  87.58758759,\n",
       "         87.68768769,  87.78778779,  87.88788789,  87.98798799,\n",
       "         88.08808809,  88.18818819,  88.28828829,  88.38838839,\n",
       "         88.48848849,  88.58858859,  88.68868869,  88.78878879,\n",
       "         88.88888889,  88.98898899,  89.08908909,  89.18918919,\n",
       "         89.28928929,  89.38938939,  89.48948949,  89.58958959,\n",
       "         89.68968969,  89.78978979,  89.88988989,  89.98998999,\n",
       "         90.09009009,  90.19019019,  90.29029029,  90.39039039,\n",
       "         90.49049049,  90.59059059,  90.69069069,  90.79079079,\n",
       "         90.89089089,  90.99099099,  91.09109109,  91.19119119,\n",
       "         91.29129129,  91.39139139,  91.49149149,  91.59159159,\n",
       "         91.69169169,  91.79179179,  91.89189189,  91.99199199,\n",
       "         92.09209209,  92.19219219,  92.29229229,  92.39239239,\n",
       "         92.49249249,  92.59259259,  92.69269269,  92.79279279,\n",
       "         92.89289289,  92.99299299,  93.09309309,  93.19319319,\n",
       "         93.29329329,  93.39339339,  93.49349349,  93.59359359,\n",
       "         93.69369369,  93.79379379,  93.89389389,  93.99399399,\n",
       "         94.09409409,  94.19419419,  94.29429429,  94.39439439,\n",
       "         94.49449449,  94.59459459,  94.69469469,  94.79479479,\n",
       "         94.89489489,  94.99499499,  95.0950951 ,  95.1951952 ,\n",
       "         95.2952953 ,  95.3953954 ,  95.4954955 ,  95.5955956 ,\n",
       "         95.6956957 ,  95.7957958 ,  95.8958959 ,  95.995996  ,\n",
       "         96.0960961 ,  96.1961962 ,  96.2962963 ,  96.3963964 ,\n",
       "         96.4964965 ,  96.5965966 ,  96.6966967 ,  96.7967968 ,\n",
       "         96.8968969 ,  96.996997  ,  97.0970971 ,  97.1971972 ,\n",
       "         97.2972973 ,  97.3973974 ,  97.4974975 ,  97.5975976 ,\n",
       "         97.6976977 ,  97.7977978 ,  97.8978979 ,  97.997998  ,\n",
       "         98.0980981 ,  98.1981982 ,  98.2982983 ,  98.3983984 ,\n",
       "         98.4984985 ,  98.5985986 ,  98.6986987 ,  98.7987988 ,\n",
       "         98.8988989 ,  98.998999  ,  99.0990991 ,  99.1991992 ,\n",
       "         99.2992993 ,  99.3993994 ,  99.4994995 ,  99.5995996 ,\n",
       "         99.6996997 ,  99.7997998 ,  99.8998999 , 100.        ]),\n",
       " 'force_alpha': [True, False],\n",
       " 'fit_prior': [True, False]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"alpha\" : np.linspace(0, 100, 1000), \"force_alpha\" : [True, False], \"fit_prior\" : [True, False]}\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:620: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([  0.        ,   0.1001001 ,   0.2002002 ,   0.3003003 ,\n",
       "         0.4004004 ,   0.5005005 ,   0.6006006 ,   0.7007007 ,\n",
       "         0.8008008 ,   0.9009009 ,   1.001001  ,   1.1011011 ,\n",
       "         1.2012012 ,   1.3013013 ,   1.4014014 ,   1.5015015 ,\n",
       "         1.6016016 ,   1.7017017 ,   1.8018018 ,   1.9019019 ,\n",
       "         2.002002  ,   2.1021021 ,   2.2022022 ,   2.3023023 ,\n",
       "         2.4024024 ,   2.5025025 ,   2.6026026 ,   2.7027027 ,\n",
       "         2.8028028 ,   2.9...\n",
       "        97.2972973 ,  97.3973974 ,  97.4974975 ,  97.5975976 ,\n",
       "        97.6976977 ,  97.7977978 ,  97.8978979 ,  97.997998  ,\n",
       "        98.0980981 ,  98.1981982 ,  98.2982983 ,  98.3983984 ,\n",
       "        98.4984985 ,  98.5985986 ,  98.6986987 ,  98.7987988 ,\n",
       "        98.8988989 ,  98.998999  ,  99.0990991 ,  99.1991992 ,\n",
       "        99.2992993 ,  99.3993994 ,  99.4994995 ,  99.5995996 ,\n",
       "        99.6996997 ,  99.7997998 ,  99.8998999 , 100.        ]),\n",
       "                         &#x27;fit_prior&#x27;: [True, False],\n",
       "                         &#x27;force_alpha&#x27;: [True, False]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={&#x27;alpha&#x27;: array([  0.        ,   0.1001001 ,   0.2002002 ,   0.3003003 ,\n",
       "         0.4004004 ,   0.5005005 ,   0.6006006 ,   0.7007007 ,\n",
       "         0.8008008 ,   0.9009009 ,   1.001001  ,   1.1011011 ,\n",
       "         1.2012012 ,   1.3013013 ,   1.4014014 ,   1.5015015 ,\n",
       "         1.6016016 ,   1.7017017 ,   1.8018018 ,   1.9019019 ,\n",
       "         2.002002  ,   2.1021021 ,   2.2022022 ,   2.3023023 ,\n",
       "         2.4024024 ,   2.5025025 ,   2.6026026 ,   2.7027027 ,\n",
       "         2.8028028 ,   2.9...\n",
       "        97.2972973 ,  97.3973974 ,  97.4974975 ,  97.5975976 ,\n",
       "        97.6976977 ,  97.7977978 ,  97.8978979 ,  97.997998  ,\n",
       "        98.0980981 ,  98.1981982 ,  98.2982983 ,  98.3983984 ,\n",
       "        98.4984985 ,  98.5985986 ,  98.6986987 ,  98.7987988 ,\n",
       "        98.8988989 ,  98.998999  ,  99.0990991 ,  99.1991992 ,\n",
       "        99.2992993 ,  99.3993994 ,  99.4994995 ,  99.5995996 ,\n",
       "        99.6996997 ,  99.7997998 ,  99.8998999 , 100.        ]),\n",
       "                         &#x27;fit_prior&#x27;: [True, False],\n",
       "                         &#x27;force_alpha&#x27;: [True, False]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: MultinomialNB</label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=np.float64(1.9019019019019021), fit_prior=False)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=np.float64(1.9019019019019021), fit_prior=False)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': array([  0.        ,   0.1001001 ,   0.2002002 ,   0.3003003 ,\n",
       "         0.4004004 ,   0.5005005 ,   0.6006006 ,   0.7007007 ,\n",
       "         0.8008008 ,   0.9009009 ,   1.001001  ,   1.1011011 ,\n",
       "         1.2012012 ,   1.3013013 ,   1.4014014 ,   1.5015015 ,\n",
       "         1.6016016 ,   1.7017017 ,   1.8018018 ,   1.9019019 ,\n",
       "         2.002002  ,   2.1021021 ,   2.2022022 ,   2.3023023 ,\n",
       "         2.4024024 ,   2.5025025 ,   2.6026026 ,   2.7027027 ,\n",
       "         2.8028028 ,   2.9...\n",
       "        97.2972973 ,  97.3973974 ,  97.4974975 ,  97.5975976 ,\n",
       "        97.6976977 ,  97.7977978 ,  97.8978979 ,  97.997998  ,\n",
       "        98.0980981 ,  98.1981982 ,  98.2982983 ,  98.3983984 ,\n",
       "        98.4984985 ,  98.5985986 ,  98.6986987 ,  98.7987988 ,\n",
       "        98.8988989 ,  98.998999  ,  99.0990991 ,  99.1991992 ,\n",
       "        99.2992993 ,  99.3993994 ,  99.4994995 ,  99.5995996 ,\n",
       "        99.6996997 ,  99.7997998 ,  99.8998999 , 100.        ]),\n",
       "                         'fit_prior': [True, False],\n",
       "                         'force_alpha': [True, False]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pre_models[0], hyperparameters, scoring=\"accuracy\")\n",
    "\n",
    "grid.fit(x_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': np.float64(1.9019019019019021),\n",
       " 'fit_prior': False,\n",
       " 'force_alpha': True}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "\n",
    "dump(clf, open(f\"../models/Multinomialmodel.sav\", \"wb\"))\n",
    "\n",
    "y_test_pred = clf.predict(x_test_vect)\n",
    "\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El modelo ha mejorado un poco al optimizarlo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
